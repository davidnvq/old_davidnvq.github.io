<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Quang Nguyen - Shervine</title><link>/</link><description></description><lastBuildDate>Tue, 21 Aug 2018 00:02:01 +0000</lastBuildDate><item><title>An example of how to generate your data in parallel with PyTorch</title><link>/blog/tutorial/2018/an-example-of-how-to-generate-your-data-in-parallel-with-pytorch/</link><description>&lt;h1 id="motivation"&gt;Motivation&lt;/h1&gt;
&lt;p&gt;Have you ever had to load a dataset that was so memory consuming that you wished a magic trick could seamlessly take care of that? Large datasets are increasingly becoming part of our lives, as we are able to harness an ever-growing quantity of data.&lt;/p&gt;
&lt;p&gt;We have to keep in mind that in some cases, even the most state-of-the-art configuration won't have enough memory space to process the data the way we used to do it. That is the reason why we need to find other ways to do that task efficiently. In this blog post, we are going to show you &lt;strong&gt;how to generate your data on multiple cores in real time&lt;/strong&gt; and feed it right away to your deep learning model.&lt;/p&gt;
&lt;p&gt;This tutorial will show you how to do so on the GPU-friendly framework PyTorch, where &lt;strong&gt;an efficient data generation scheme&lt;/strong&gt; is crucial to leverage the full â€¦&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Shervine</dc:creator><pubDate>Tue, 21 Aug 2018 00:02:01 +0000</pubDate><guid isPermaLink="false">tag:None,2018-08-21:/blog/tutorial/2018/an-example-of-how-to-generate-your-data-in-parallel-with-pytorch/</guid><category>Data Parallel</category><category>Data Loader</category><category>Pytorch</category><category>TUTORIAL</category></item></channel></rss>